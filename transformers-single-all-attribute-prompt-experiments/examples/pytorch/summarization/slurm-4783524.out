5
/var/spool/slurmd/job4783524/slurm_script: line 16: activate: No such file or directory
06/19/2022 20:41:26 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
06/19/2022 20:41:26 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.STEPS,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.1,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all-k=5-out-domain/runs/Jun19_20-41-22_g3061,
logging_first_step=True,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=different_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=OptimizerNames.ADAMW_HF,
output_dir=/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all-k=5-out-domain,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=300,
per_device_train_batch_size=35,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=False,
report_to=[],
resume_from_checkpoint=None,
run_name=/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all-k=5-out-domain,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=2,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
06/19/2022 20:41:26 - WARNING - datasets.builder - Using custom data configuration default-b66aecc0fd0c2c68
06/19/2022 20:41:26 - INFO - datasets.builder - Overwrite dataset info from restored data version.
06/19/2022 20:41:26 - INFO - datasets.info - Loading Dataset info from /mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-b66aecc0fd0c2c68/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b
06/19/2022 20:41:26 - WARNING - datasets.builder - Reusing dataset json (/mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-b66aecc0fd0c2c68/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)
06/19/2022 20:41:26 - INFO - datasets.info - Loading Dataset info from /mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-b66aecc0fd0c2c68/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 125.80it/s]
[INFO|configuration_utils.py:651] 2022-06-19 20:41:26,860 >> loading configuration file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/config.json
[INFO|configuration_utils.py:689] 2022-06-19 20:41:26,864 >> Model config T5Config {
  "_name_or_path": "/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 3072,
  "d_kv": 64,
  "d_model": 768,
  "decoder_start_token_id": 0,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 12,
  "num_heads": 12,
  "num_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.17.0.dev0",
  "use_cache": true,
  "vocab_size": 32100
}

[INFO|tokenization_utils_base.py:1703] 2022-06-19 20:41:26,869 >> Didn't find file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:41:26,870 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/spiece.model
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:41:26,870 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/tokenizer.json
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:41:26,870 >> loading file None
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:41:26,870 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/special_tokens_map.json
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:41:26,870 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/tokenizer_config.json
[INFO|modeling_utils.py:1435] 2022-06-19 20:41:27,003 >> loading weights file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/pytorch_model.bin
[INFO|modeling_utils.py:1704] 2022-06-19 20:41:29,739 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.

[INFO|modeling_utils.py:1712] 2022-06-19 20:41:29,739 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500.
If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.
Running tokenizer on validation dataset:   0%|          | 0/12 [00:00<?, ?ba/s]06/19/2022 20:41:29 - INFO - datasets.arrow_dataset - Caching processed dataset at /mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-b66aecc0fd0c2c68/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-840aadfbb2a1fe2f.arrow
Running tokenizer on validation dataset:   8%|▊         | 1/12 [00:00<00:02,  5.22ba/s]Running tokenizer on validation dataset:  17%|█▋        | 2/12 [00:00<00:01,  5.40ba/s]Running tokenizer on validation dataset:  25%|██▌       | 3/12 [00:00<00:01,  5.30ba/s]Running tokenizer on validation dataset:  33%|███▎      | 4/12 [00:00<00:01,  5.27ba/s]Running tokenizer on validation dataset:  42%|████▏     | 5/12 [00:00<00:01,  5.55ba/s]Running tokenizer on validation dataset:  50%|█████     | 6/12 [00:01<00:01,  5.72ba/s]Running tokenizer on validation dataset:  58%|█████▊    | 7/12 [00:01<00:00,  6.06ba/s]Running tokenizer on validation dataset:  67%|██████▋   | 8/12 [00:01<00:00,  5.78ba/s]Running tokenizer on validation dataset:  75%|███████▌  | 9/12 [00:01<00:00,  5.79ba/s]Running tokenizer on validation dataset:  83%|████████▎ | 10/12 [00:01<00:00,  5.10ba/s]Running tokenizer on validation dataset:  92%|█████████▏| 11/12 [00:02<00:00,  4.88ba/s]Running tokenizer on validation dataset: 100%|██████████| 12/12 [00:02<00:00,  5.65ba/s]
06/19/2022 20:41:50 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:2387] 2022-06-19 20:41:50,502 >> ***** Running Evaluation *****
[INFO|trainer.py:2389] 2022-06-19 20:41:50,502 >>   Num examples = 11205
[INFO|trainer.py:2392] 2022-06-19 20:41:50,502 >>   Batch size = 300
  0%|          | 0/38 [00:00<?, ?it/s]  5%|▌         | 2/38 [00:00<00:16,  2.19it/s]  8%|▊         | 3/38 [00:01<00:22,  1.55it/s] 11%|█         | 4/38 [00:02<00:22,  1.52it/s] 13%|█▎        | 5/38 [00:03<00:21,  1.55it/s] 16%|█▌        | 6/38 [00:03<00:19,  1.62it/s] 18%|█▊        | 7/38 [00:04<00:19,  1.55it/s] 21%|██        | 8/38 [00:05<00:25,  1.18it/s] 24%|██▎       | 9/38 [00:06<00:21,  1.34it/s] 26%|██▋       | 10/38 [00:06<00:21,  1.31it/s] 29%|██▉       | 11/38 [00:07<00:21,  1.28it/s] 32%|███▏      | 12/38 [00:08<00:19,  1.36it/s] 34%|███▍      | 13/38 [00:09<00:19,  1.30it/s] 37%|███▋      | 14/38 [00:10<00:18,  1.28it/s] 39%|███▉      | 15/38 [00:10<00:16,  1.40it/s] 42%|████▏     | 16/38 [00:11<00:15,  1.40it/s] 45%|████▍     | 17/38 [00:12<00:16,  1.27it/s] 47%|████▋     | 18/38 [00:13<00:16,  1.23it/s] 50%|█████     | 19/38 [00:13<00:13,  1.36it/s] 53%|█████▎    | 20/38 [00:14<00:11,  1.51it/s] 55%|█████▌    | 21/38 [00:14<00:10,  1.57it/s] 58%|█████▊    | 22/38 [00:15<00:10,  1.58it/s] 61%|██████    | 23/38 [00:15<00:08,  1.67it/s] 63%|██████▎   | 24/38 [00:16<00:08,  1.65it/s] 66%|██████▌   | 25/38 [00:17<00:08,  1.46it/s] 68%|██████▊   | 26/38 [00:18<00:08,  1.47it/s] 71%|███████   | 27/38 [00:19<00:08,  1.31it/s] 74%|███████▎  | 28/38 [00:20<00:08,  1.16it/s] 76%|███████▋  | 29/38 [00:20<00:06,  1.29it/s] 79%|███████▉  | 30/38 [00:21<00:06,  1.26it/s] 82%|████████▏ | 31/38 [00:22<00:05,  1.23it/s] 84%|████████▍ | 32/38 [00:23<00:04,  1.30it/s] 87%|████████▋ | 33/38 [00:23<00:03,  1.35it/s] 89%|████████▉ | 34/38 [00:24<00:03,  1.25it/s] 92%|█████████▏| 35/38 [00:25<00:02,  1.16it/s] 95%|█████████▍| 36/38 [00:26<00:01,  1.22it/s] 97%|█████████▋| 37/38 [00:27<00:00,  1.25it/s]100%|██████████| 38/38 [00:27<00:00,  1.50it/s]06/19/2022 20:42:27 - INFO - datasets.metric - Removing /mmfs1/home/artidoro/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow
Traceback (most recent call last):
  File "/mmfs1/gscratch/argon/artidoro/eva_transformers/examples/pytorch/summarization/run_summarization.py", line 938, in <module>
    main()
  File "/mmfs1/gscratch/argon/artidoro/eva_transformers/examples/pytorch/summarization/run_summarization.py", line 880, in main
    metrics = trainer.evaluate(max_length=max_length, num_beams=num_beams, metric_key_prefix="eval")
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/transformers/trainer_seq2seq.py", line 70, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/transformers/trainer.py", line 2255, in evaluate
    output = eval_loop(
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/transformers/trainer.py", line 2503, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
  File "/mmfs1/gscratch/argon/artidoro/eva_transformers/examples/pytorch/summarization/run_summarization.py", line 709, in compute_metrics_multi_attr
    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/datasets/metric.py", line 422, in compute
    os.remove(file_path)
FileNotFoundError: [Errno 2] No such file or directory: '/mmfs1/home/artidoro/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow'
100%|██████████| 38/38 [00:36<00:00,  1.05it/s]
