10
/var/spool/slurmd/job4783532/slurm_script: line 16: activate: No such file or directory
06/19/2022 20:43:25 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
06/19/2022 20:43:25 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.STEPS,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.1,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all-k=10-out-domain/runs/Jun19_20-43-21_g3061,
logging_first_step=True,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=different_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=OptimizerNames.ADAMW_HF,
output_dir=/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all-k=10-out-domain,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=300,
per_device_train_batch_size=35,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=False,
report_to=[],
resume_from_checkpoint=None,
run_name=/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all-k=10-out-domain,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=2,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
06/19/2022 20:43:25 - WARNING - datasets.builder - Using custom data configuration default-62b60951a69f8b1f
06/19/2022 20:43:25 - INFO - datasets.builder - Overwrite dataset info from restored data version.
06/19/2022 20:43:25 - INFO - datasets.info - Loading Dataset info from /mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-62b60951a69f8b1f/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b
06/19/2022 20:43:25 - WARNING - datasets.builder - Reusing dataset json (/mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-62b60951a69f8b1f/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)
06/19/2022 20:43:25 - INFO - datasets.info - Loading Dataset info from /mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-62b60951a69f8b1f/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 186.67it/s]
[INFO|configuration_utils.py:651] 2022-06-19 20:43:25,982 >> loading configuration file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/config.json
[INFO|configuration_utils.py:689] 2022-06-19 20:43:25,986 >> Model config T5Config {
  "_name_or_path": "/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 3072,
  "d_kv": 64,
  "d_model": 768,
  "decoder_start_token_id": 0,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 12,
  "num_heads": 12,
  "num_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.17.0.dev0",
  "use_cache": true,
  "vocab_size": 32100
}

[INFO|tokenization_utils_base.py:1703] 2022-06-19 20:43:25,990 >> Didn't find file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:43:25,991 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/spiece.model
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:43:25,991 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/tokenizer.json
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:43:25,991 >> loading file None
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:43:25,991 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/special_tokens_map.json
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:43:25,991 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/tokenizer_config.json
[INFO|modeling_utils.py:1435] 2022-06-19 20:43:26,134 >> loading weights file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/pytorch_model.bin
[INFO|modeling_utils.py:1704] 2022-06-19 20:43:28,816 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.

[INFO|modeling_utils.py:1712] 2022-06-19 20:43:28,816 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500.
If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.
Running tokenizer on validation dataset:   0%|          | 0/7 [00:00<?, ?ba/s]06/19/2022 20:43:29 - INFO - datasets.arrow_dataset - Caching processed dataset at /mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-62b60951a69f8b1f/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-722713b673d38684.arrow
Running tokenizer on validation dataset:  14%|█▍        | 1/7 [00:00<00:01,  4.64ba/s]Running tokenizer on validation dataset:  29%|██▊       | 2/7 [00:00<00:01,  4.42ba/s]Running tokenizer on validation dataset:  43%|████▎     | 3/7 [00:00<00:00,  4.72ba/s]Running tokenizer on validation dataset:  57%|█████▋    | 4/7 [00:00<00:00,  5.30ba/s]Running tokenizer on validation dataset:  71%|███████▏  | 5/7 [00:00<00:00,  5.22ba/s]Running tokenizer on validation dataset:  86%|████████▌ | 6/7 [00:01<00:00,  5.12ba/s]Running tokenizer on validation dataset: 100%|██████████| 7/7 [00:01<00:00,  5.58ba/s]
06/19/2022 20:43:48 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:2387] 2022-06-19 20:43:48,748 >> ***** Running Evaluation *****
[INFO|trainer.py:2389] 2022-06-19 20:43:48,748 >>   Num examples = 6225
[INFO|trainer.py:2392] 2022-06-19 20:43:48,748 >>   Batch size = 300
  0%|          | 0/21 [00:00<?, ?it/s] 10%|▉         | 2/21 [00:01<00:09,  1.99it/s] 14%|█▍        | 3/21 [00:01<00:10,  1.72it/s] 19%|█▉        | 4/21 [00:02<00:13,  1.30it/s] 24%|██▍       | 5/21 [00:04<00:15,  1.02it/s] 29%|██▊       | 6/21 [00:05<00:14,  1.04it/s] 33%|███▎      | 7/21 [00:05<00:12,  1.11it/s] 38%|███▊      | 8/21 [00:06<00:11,  1.10it/s] 43%|████▎     | 9/21 [00:07<00:10,  1.15it/s] 48%|████▊     | 10/21 [00:08<00:10,  1.07it/s] 52%|█████▏    | 11/21 [00:09<00:08,  1.18it/s] 57%|█████▋    | 12/21 [00:09<00:07,  1.26it/s] 62%|██████▏   | 13/21 [00:10<00:05,  1.37it/s] 67%|██████▋   | 14/21 [00:11<00:05,  1.25it/s] 71%|███████▏  | 15/21 [00:12<00:05,  1.16it/s] 76%|███████▌  | 16/21 [00:13<00:04,  1.02it/s] 81%|████████  | 17/21 [00:14<00:03,  1.04it/s] 86%|████████▌ | 18/21 [00:15<00:02,  1.11it/s] 90%|█████████ | 19/21 [00:16<00:01,  1.07it/s] 95%|█████████▌| 20/21 [00:17<00:00,  1.13it/s]100%|██████████| 21/21 [00:17<00:00,  1.21it/s]06/19/2022 20:44:12 - INFO - datasets.metric - Removing /mmfs1/home/artidoro/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow
Traceback (most recent call last):
  File "/mmfs1/gscratch/argon/artidoro/eva_transformers/examples/pytorch/summarization/run_summarization.py", line 938, in <module>
    main()
  File "/mmfs1/gscratch/argon/artidoro/eva_transformers/examples/pytorch/summarization/run_summarization.py", line 880, in main
    metrics = trainer.evaluate(max_length=max_length, num_beams=num_beams, metric_key_prefix="eval")
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/transformers/trainer_seq2seq.py", line 70, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/transformers/trainer.py", line 2255, in evaluate
    output = eval_loop(
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/transformers/trainer.py", line 2503, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
  File "/mmfs1/gscratch/argon/artidoro/eva_transformers/examples/pytorch/summarization/run_summarization.py", line 709, in compute_metrics_multi_attr
    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/datasets/metric.py", line 422, in compute
    os.remove(file_path)
FileNotFoundError: [Errno 2] No such file or directory: '/mmfs1/home/artidoro/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow'
100%|██████████| 21/21 [00:22<00:00,  1.08s/it]
