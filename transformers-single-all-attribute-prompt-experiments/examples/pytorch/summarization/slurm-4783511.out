1
/var/spool/slurmd/job4783511/slurm_script: line 16: activate: No such file or directory
06/19/2022 20:38:30 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
06/19/2022 20:38:30 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.STEPS,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.1,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all-k=1-out-domain/runs/Jun19_20-38-23_g3060,
logging_first_step=True,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=different_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=OptimizerNames.ADAMW_HF,
output_dir=/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all-k=1-out-domain,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=300,
per_device_train_batch_size=35,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=False,
report_to=[],
resume_from_checkpoint=None,
run_name=/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all-k=1-out-domain,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=2,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
06/19/2022 20:38:30 - WARNING - datasets.builder - Using custom data configuration default-2774297d9ce58ee0
06/19/2022 20:38:30 - INFO - datasets.builder - Generating dataset json (/mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-2774297d9ce58ee0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)
Downloading and preparing dataset json/default to /mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-2774297d9ce58ee0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 7681.88it/s]
06/19/2022 20:38:30 - INFO - datasets.utils.download_manager - Downloading took 0.0 min
06/19/2022 20:38:30 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 259.87it/s]
06/19/2022 20:38:30 - INFO - datasets.utils.info_utils - Unable to verify checksums.
06/19/2022 20:38:30 - INFO - datasets.builder - Generating split validation
06/19/2022 20:38:30 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.
Dataset json downloaded and prepared to /mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-2774297d9ce58ee0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 137.02it/s]
[INFO|configuration_utils.py:651] 2022-06-19 20:38:30,640 >> loading configuration file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/config.json
[INFO|configuration_utils.py:689] 2022-06-19 20:38:30,644 >> Model config T5Config {
  "_name_or_path": "/gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "d_ff": 3072,
  "d_kv": 64,
  "d_model": 768,
  "decoder_start_token_id": 0,
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 12,
  "num_heads": 12,
  "num_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.17.0.dev0",
  "use_cache": true,
  "vocab_size": 32100
}

[INFO|tokenization_utils_base.py:1703] 2022-06-19 20:38:30,648 >> Didn't find file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:38:30,648 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/spiece.model
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:38:30,649 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/tokenizer.json
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:38:30,649 >> loading file None
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:38:30,649 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/special_tokens_map.json
[INFO|tokenization_utils_base.py:1786] 2022-06-19 20:38:30,649 >> loading file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/tokenizer_config.json
[INFO|modeling_utils.py:1435] 2022-06-19 20:38:30,765 >> loading weights file /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500/pytorch_model.bin
[INFO|modeling_utils.py:1704] 2022-06-19 20:38:33,277 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.

[INFO|modeling_utils.py:1712] 2022-06-19 20:38:33,277 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /gscratch/argon/artidoro/eventsrealm/real_events/outputs/gold-v1.1-prompt-t5-merged-entities-k_prompts-1-single-all/checkpoint-5500.
If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.
Running tokenizer on validation dataset:   0%|          | 0/11 [00:00<?, ?ba/s]06/19/2022 20:38:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /mmfs1/home/artidoro/.cache/huggingface/datasets/json/default-2774297d9ce58ee0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-94305e55d8cc34a4.arrow
Running tokenizer on validation dataset:   9%|▉         | 1/11 [00:00<00:01,  6.19ba/s]Running tokenizer on validation dataset:  18%|█▊        | 2/11 [00:00<00:01,  6.62ba/s]Running tokenizer on validation dataset:  27%|██▋       | 3/11 [00:00<00:01,  6.20ba/s]Running tokenizer on validation dataset:  36%|███▋      | 4/11 [00:00<00:01,  6.49ba/s]Running tokenizer on validation dataset:  45%|████▌     | 5/11 [00:00<00:00,  6.73ba/s]Running tokenizer on validation dataset:  55%|█████▍    | 6/11 [00:00<00:00,  7.27ba/s]Running tokenizer on validation dataset:  64%|██████▎   | 7/11 [00:01<00:00,  7.28ba/s]Running tokenizer on validation dataset:  73%|███████▎  | 8/11 [00:01<00:00,  6.95ba/s]Running tokenizer on validation dataset:  82%|████████▏ | 9/11 [00:01<00:00,  6.81ba/s]Running tokenizer on validation dataset:  91%|█████████ | 10/11 [00:01<00:00,  5.80ba/s]Running tokenizer on validation dataset: 100%|██████████| 11/11 [00:01<00:00,  6.88ba/s]
06/19/2022 20:38:48 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:2387] 2022-06-19 20:38:48,831 >> ***** Running Evaluation *****
[INFO|trainer.py:2389] 2022-06-19 20:38:48,831 >>   Num examples = 10209
[INFO|trainer.py:2392] 2022-06-19 20:38:48,831 >>   Batch size = 300
  0%|          | 0/35 [00:00<?, ?it/s]  6%|▌         | 2/35 [00:00<00:13,  2.39it/s]  9%|▊         | 3/35 [00:01<00:18,  1.69it/s] 11%|█▏        | 4/35 [00:02<00:18,  1.68it/s] 14%|█▍        | 5/35 [00:02<00:17,  1.75it/s] 17%|█▋        | 6/35 [00:03<00:17,  1.69it/s] 20%|██        | 7/35 [00:04<00:22,  1.27it/s] 23%|██▎       | 8/35 [00:05<00:21,  1.26it/s] 26%|██▌       | 9/35 [00:06<00:19,  1.31it/s] 29%|██▊       | 10/35 [00:06<00:19,  1.31it/s] 31%|███▏      | 11/35 [00:07<00:16,  1.45it/s] 34%|███▍      | 12/35 [00:08<00:16,  1.40it/s] 37%|███▋      | 13/35 [00:08<00:15,  1.46it/s] 40%|████      | 14/35 [00:09<00:13,  1.54it/s] 43%|████▎     | 15/35 [00:10<00:12,  1.56it/s] 46%|████▌     | 16/35 [00:10<00:13,  1.40it/s] 49%|████▊     | 17/35 [00:11<00:11,  1.54it/s] 51%|█████▏    | 18/35 [00:11<00:09,  1.70it/s] 54%|█████▍    | 19/35 [00:12<00:09,  1.78it/s] 57%|█████▋    | 20/35 [00:12<00:08,  1.79it/s] 60%|██████    | 21/35 [00:13<00:07,  1.91it/s] 63%|██████▎   | 22/35 [00:13<00:07,  1.85it/s] 66%|██████▌   | 23/35 [00:14<00:07,  1.62it/s] 69%|██████▊   | 24/35 [00:15<00:07,  1.53it/s] 71%|███████▏  | 25/35 [00:16<00:07,  1.39it/s] 74%|███████▍  | 26/35 [00:17<00:07,  1.21it/s] 77%|███████▋  | 27/35 [00:18<00:06,  1.25it/s] 80%|████████  | 28/35 [00:18<00:05,  1.26it/s] 83%|████████▎ | 29/35 [00:19<00:04,  1.38it/s] 86%|████████▌ | 30/35 [00:20<00:03,  1.45it/s] 89%|████████▊ | 31/35 [00:20<00:02,  1.36it/s] 91%|█████████▏| 32/35 [00:21<00:02,  1.26it/s] 94%|█████████▍| 33/35 [00:22<00:01,  1.37it/s] 97%|█████████▋| 34/35 [00:23<00:00,  1.39it/s]100%|██████████| 35/35 [00:23<00:00,  1.80it/s]06/19/2022 20:39:20 - INFO - datasets.metric - Removing /mmfs1/home/artidoro/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow
Traceback (most recent call last):
  File "/mmfs1/gscratch/argon/artidoro/eva_transformers/examples/pytorch/summarization/run_summarization.py", line 938, in <module>
    main()
  File "/mmfs1/gscratch/argon/artidoro/eva_transformers/examples/pytorch/summarization/run_summarization.py", line 880, in main
    metrics = trainer.evaluate(max_length=max_length, num_beams=num_beams, metric_key_prefix="eval")
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/transformers/trainer_seq2seq.py", line 70, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/transformers/trainer.py", line 2255, in evaluate
    output = eval_loop(
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/transformers/trainer.py", line 2503, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
  File "/mmfs1/gscratch/argon/artidoro/eva_transformers/examples/pytorch/summarization/run_summarization.py", line 709, in compute_metrics_multi_attr
    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)
  File "/gscratch/argon/artidoro/miniconda3/envs/eva_transformers/lib/python3.9/site-packages/datasets/metric.py", line 422, in compute
    os.remove(file_path)
FileNotFoundError: [Errno 2] No such file or directory: '/mmfs1/home/artidoro/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow'
100%|██████████| 35/35 [00:30<00:00,  1.14it/s]
